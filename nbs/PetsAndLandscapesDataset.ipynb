{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.append(str(Path.cwd().parent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from typing import Any, List, Iterable, Tuple, NamedTuple, TypedDict\n",
    "\n",
    "from uuid import uuid4\n",
    "import cv2\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import polars as pl\n",
    "import torchvision\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "from my_project.di import get_injector\n",
    "from my_project.directories.interface import InputDir, OutputDir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "injector = get_injector()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = injector.get(InputDir)\n",
    "output_dir = injector.get(OutputDir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the pets dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_filenames(list_file: Path) -> Iterable[str]:\n",
    "    with list_file.open(\"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line.startswith(\"#\"):\n",
    "                continue\n",
    "            if not line:\n",
    "                continue\n",
    "            (img_name, _rest) = line.split(\" \", 1)\n",
    "            yield img_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BBox(NamedTuple):\n",
    "    center_x: float\n",
    "    center_y: float\n",
    "    width: float\n",
    "    height: float\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_bbox(file_path: Path) -> BBox:\n",
    "    assert file_path.is_file(), file_path\n",
    "    tree = ElementTree.parse(file_path)\n",
    "    bbox = tree.find(\"./object/bndbox\")\n",
    "    xmin = int(bbox.find(\"./xmin\").text)\n",
    "    xmax = int(bbox.find(\"./xmax\").text)\n",
    "    ymin = int(bbox.find(\"./ymin\").text)\n",
    "    ymax = int(bbox.find(\"./ymax\").text)\n",
    "\n",
    "    center_x = (xmin + xmax) / 2\n",
    "    center_y = (ymin + ymax) / 2\n",
    "    width = xmax - xmin\n",
    "    height = ymax - ymin\n",
    "\n",
    "    return BBox(center_x, center_y, width, height)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_image_dir = input_dir / \"pet\" / \"images\"\n",
    "pet_xml_dir = input_dir / \"pet\" / \"annotations\" / \"xmls\"\n",
    "pet_list_file = input_dir / \"pet\" / \"annotations\" / \"list.txt\"\n",
    "landscape_image_dir = input_dir / \"landscapes\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Corrupt JPEG data: premature end of data segment\n",
      "Corrupt JPEG data: 240 extraneous bytes before marker 0xd9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to read image /inputs/landscapes/00000051_(3).jpg\n"
     ]
    }
   ],
   "source": [
    "output_size = 224\n",
    "records = []\n",
    "dataset_output_dir = output_dir / \"pets_and_landscapes\"\n",
    "dataset_output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "for filename in [\n",
    "    filename\n",
    "    for filename in load_filenames(pet_list_file)\n",
    "    if (pet_xml_dir / f\"{filename}.xml\").is_file()\n",
    "]:\n",
    "    xml_file = pet_xml_dir / f\"{filename}.xml\"\n",
    "    bbox = load_bbox(xml_file)\n",
    "    image_path = pet_image_dir / f\"{filename}.jpg\"\n",
    "    image = torchvision.io.read_image(\n",
    "        str(image_path), mode=torchvision.io.ImageReadMode.RGB\n",
    "    )\n",
    "    annotation_path = pet_xml_dir / f\"{filename}.xml\"\n",
    "    bbox = load_bbox(annotation_path)\n",
    "\n",
    "    channels, img_height, img_width = image.shape\n",
    "    assert channels == 3\n",
    "\n",
    "    bbox_factor = BBox(\n",
    "        center_x=bbox.center_x / img_width,\n",
    "        center_y=bbox.center_y / img_height,\n",
    "        width=bbox.width / img_width,\n",
    "        height=bbox.height / img_height,\n",
    "    )\n",
    "    resized_image = torchvision.transforms.functional.resize(\n",
    "        image, (output_size, output_size)\n",
    "    )\n",
    "\n",
    "    id = uuid4()\n",
    "    output_filename = f\"{id}.jpg\"\n",
    "    torchvision.io.write_jpeg(\n",
    "        resized_image, str(dataset_output_dir / output_filename), quality=90\n",
    "    )\n",
    "    records.append(\n",
    "        {\n",
    "            \"filename\": output_filename,\n",
    "            \"class\": 1,\n",
    "            \"bbox_center_x\": bbox_factor.center_x,\n",
    "            \"bbox_center_y\": bbox_factor.center_y,\n",
    "            \"bbox_width\": bbox_factor.width,\n",
    "            \"bbox_height\": bbox_factor.height,\n",
    "        }\n",
    "    )\n",
    "\n",
    "for filename in landscape_image_dir.glob(\"*.jpg\"):\n",
    "    try:\n",
    "        image = torchvision.io.read_image(\n",
    "            str(filename), mode=torchvision.io.ImageReadMode.RGB\n",
    "        )\n",
    "    except RuntimeError:\n",
    "        print(\"Failed to read image\", filename)\n",
    "        continue\n",
    "    channels, img_height, img_width = image.shape\n",
    "    assert channels == 3\n",
    "    resized_image = torchvision.transforms.functional.resize(\n",
    "        image, (output_size, output_size)\n",
    "    )\n",
    "    id = uuid4()\n",
    "    output_filename = f\"{id}.jpg\"\n",
    "    torchvision.io.write_jpeg(\n",
    "        resized_image, str(dataset_output_dir / output_filename), quality=90\n",
    "    )\n",
    "    records.append(\n",
    "        {\n",
    "            \"filename\": output_filename,\n",
    "            \"class\": 0,\n",
    "            \"bbox_center_x\": 0.5,\n",
    "            \"bbox_center_y\": 0.5,\n",
    "            \"bbox_width\": 1.0,\n",
    "            \"bbox_height\": 1.0,\n",
    "        }\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.DataFrame(records).write_csv(dataset_output_dir / \"pets_and_ladscapes.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
